# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, I build and optimized an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.</br>

In this project, I had the opportunity to create and optimize an ML pipeline. Provided a **custom-coded model—a standard Scikit-learn Logistic Regression**—the hyperparameters of which **optimized using HyperDrive**. I also used **AutoML to build and optimize a model** on the same dataset, so that I can **compare the results of the two methods**. </br>
![You can see the main steps that I took in the diagram below:](https://github.com/AnshuTrivedi/Project-1-Optimizing_ML-Pipeline_in_Azure/blob/master/Images/project_overview.png)


## Summary

**Classification using a Bank Marketing Dataset**</br>
We use the UCI Bank Marketing dataset to predict if client will subscribe term deposit with the bank.</br>
The classification goal is to predict if the client will subscribe to a term deposit with the bank.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

**What are the benefits of the parameter sampler you chose?**
Random sampling supports discrete and continuous hyperparameters. It supports early termination of low-performance runs. Some users do an initial search with random sampling and then refine the search space to improve results.
Grid sampling supports discrete hyperparameters. Use grid sampling if you can budget to exhaustively search over the search space.
Bayesian sampling is recommended if you have enough budget to explore the hyperparameter space. Bayesian sampling does not support early termination.

**What are the benefits of the early stopping policy you chose?**
For more aggressive savings, use Bandit Policy with a smaller allowable slack 

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**


## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
Cluster deletion code included in code.
![]()

## References :
[classification-bank-marketing-all-features](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning/classification-bank-marketing-all-features)
[How i decided early termination policy and sampling space](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#specify-an-early-termination-policy)